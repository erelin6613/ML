{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"img_rec.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"BADdZuPV_OWM","colab_type":"code","outputId":"87f43f35-c347-4e6f-a2b8-f2533b0e643b","executionInfo":{"status":"ok","timestamp":1570903860791,"user_tz":-180,"elapsed":1924754,"user":{"displayName":"Valentina Figurskaya","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC9898tz-Bcx7lz3a8qRwkMEU3TbfJsZmMT8BtX=s64","userId":"03885377616144133547"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["import os\n","import time\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","from keras.preprocessing.image import load_img, ImageDataGenerator, img_to_array, array_to_img\n","from keras.applications.vgg16 import preprocess_input, VGG16\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n","from keras.utils import to_categorical, normalize\n","from sklearn.metrics import confusion_matrix\n","from sklearn.model_selection import train_test_split\n","from keras.models import load_model\n","import os\n","import cv2\n","import tensorflow as tf\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","config = tf.ConfigProto(\n","        device_count = {'GPU': 0}\n","    )\n","sess = tf.Session(config=config)\n","#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","\n","#model = load_model('new_model.h5')\n","\n","def plots(ims, figsize=(12,6), rows=1, interp=False, titles=None):\n","    if type(ims[0]) is np.ndarray:\n","        ims = np.array(ims).astype(np.uint8)\n","        if (ims.shape[-1] != 3):\n","            ims = ims.transpose((0,2,3,1))\n","    f = plt.figure(figsize=figsize)\n","    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n","    for i in range(len(ims)):\n","        sp = f.add_subplot(rows, cols, i+1)\n","        sp.axis('Off')\n","        if titles is not None:\n","            sp.set_title(titles[i], fontsize=16)\n","        plt.imshow(ims[i])\n","        plt.show()\n","        print('plots should have been run')\n","\n","\n","def create_data(path):\n","\n","  data = []\n","  labels = []\n","\n","  for folder in os.listdir(path):\n","    for pic in os.listdir(os.path.join(path,folder)):\n","      label = str(folder)\n","      img = os.path.join(os.path.join(path,folder), pic)\n","      img = cv2.imread(img)\n","      data.append([np.array(img), label])\n","      #labels.append(label)\n","\n","  return data\n","\n","\n","train_path = '/content/gdrive/My Drive/Colab_Notebooks/google_recaptcha_set/recaptcha_set/3x3/train'\n","test_path = '/content/gdrive/My Drive/Colab_Notebooks/google_recaptcha_set/recaptcha_set/3x3/test'\n","\n","#train_path = './coding/intel_img/seg_train'\n","#test_path = './coding/intel_img/seg_test'\n","#valid_path = '/home/val/google_recaptcha_set/recaptcha_set/3x3/valid'\n","\n","train_data = [row[0] for row in create_data(train_path)]\n","train_data = np.asarray(train_data)\n","train_data = normalize(train_data)\n","\n","train_labels = np.asarray([row[1] for row in create_data(train_path)])\n","train_labels = np.asarray(train_labels)\n","#train_labels = to_categorical(train_labels)\n","\n","test_data = [row[0] for row in create_data(test_path)]\n","test_data = np.asarray(test_data)\n","test_data = normalize(test_data)\n","\n","test_labels = np.asarray([row[1] for row in create_data(test_path)])\n","test_labels = np.asarray(test_labels)\n","#test_labels = to_categorical(test_labels)\n","#test_labels = np.asarray(test_labels)\n","\n","print(train_labels)\n","#train_data, train_labels = create_data(train_path)\n","#test_data, test_labels = create_data(test_path)\n","\n","\n","label_encoder = LabelEncoder()\n","int_train_labels = label_encoder.fit_transform(train_labels)\n","#one_hot_enc = OneHotEncoder()\n","int_train_labels = to_categorical(int_train_labels)\n","#one_hot_train_enc = one_hot_train_enc.todense()\n","int_test_labels = label_encoder.fit_transform(test_labels)\n","int_test_labels = to_categorical(int_test_labels)\n","#one_hot_enc = OneHotEncoder()\n","#one_hot_test_enc = one_hot_enc.fit(int_test_labels.reshape(len(int_test_labels), 1))\n","#one_hot_test_enc = one_hot_test_enc.todense()\n","\n","print(int_train_labels)\n","\n","#print(train_labels)\n","#print()\n","\n","#categories = ['bus', 'traffic_lights', 'crosswalks', 'bicycles',\n","#        'fire_hydrant', 'cars', 'chimneys', 'stairs', 'bridges']\n","\n","#(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","#y_train = np_utils.to_categorical(y_train, num_classes)\n","#y_test = np_utils.to_categorical(y_test, num_classes)\n","\n","#X_train, X_test, y_train, y_test = train_test_split(images, labels)\n","\n","model = Sequential()\n","model.add(Conv2D(32, input_shape=(130, 130, 3), kernel_size=(3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(32, kernel_size=(2, 2)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(32, kernel_size=(2, 2)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(32, kernel_size=(2, 2)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(64, kernel_size=(2, 2)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Flatten())\n","model.add(Dense(64))\n","model.add(Dropout(0.5))\n","model.add(Activation('sigmoid'))\n","\n","#model.add(Flatten())\n","model.add(Dense(10, activation=tf.nn.softmax))\n","#model.add(Flatten())\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","model.fit(train_data, int_train_labels, steps_per_epoch=50, epochs=10, validation_split=0.2, validation_steps=20)\n","\n","print(model.metrics_names)\n","print(model.evaluate(test_data, int_test_labels))\n","\n","model.save('new_model.h5')\n","\n","\"\"\"pics = []\n","pic = load_img('./pic_2_23.jpg', target_size=(130, 130, 3), color_mode='rgb')\n","pic = img_to_array(pic)\n","pic = pic.reshape((-1, 130, 130, 3))\n","pics.append(pic)\n","y_prob = model.predict_classes(pics) \n","#y_classes = y_prob.argmax(axis=-1)\n","print(y_prob)\"\"\"\n","\n","\n","#model.save_weights('cnn_recaptcha_weights.h5')\n","#model.save('cnn_recaptcha.h5')\n","#print(model.summary())\n","\n","\n","\n","\n","#conf_mat = confusion_matrix(test_labels, predected_labels)\n","\n","\"\"\"\n","batch_size = 16\n","train_datagen = ImageDataGenerator(rotation_range=0, width_shift_range=0.25,\n","\t\t\t\t\t\t\t\t\theight_shift_range=0.25, rescale=1./255, \n","\t\t\t\t\t\t\t\t\tshear_range=0.2, zoom_range=0.15, \n","\t\t\t\t\t\t\t\t\thorizontal_flip=True, fill_mode='nearest')\n","#for root, dirs, files in os.walk(path):\n","#   for name in files:\n","#   \timage = load_img(os.path.join(root, name))\n","#   \tx = img_to_array(image)\n","#   \tx = x.reshape((1,)+x.shape)\n","#   \tmodel.predict(x)\n","\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = train_datagen.flow_from_directory(path+'/train', target_size=(131, 131), \n","\t\t\t\t\t\t\t\t\t\t\t\t\t\tbatch_size=batch_size, class_mode='binary')\n","\n","validation_generator = test_datagen.flow_from_directory(path+'/validation', target_size=(131, 131),\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tbatch_size=batch_size, class_mode='binary')\n","\n","model.fit_generator(train_generator, steps_per_epoch=2000//batch_size, epochs=50,\n","\t\t\t\t\tvalidation_data=validation_generator, validation_steps=800//batch_size)\n","\n","model.save_weights('model_recaptcha.h5')\n","\n","j=0\n","\n","#mini_pic_sizes = [(0, 0, 131, 131), (0, 131, 131, 262), (0, 262, 131, 392),\n","#\t\t\t\t\t(131, 0, 262, 131), (131, 131, 262, 262), (131, 262, 262, 392),\n","#\t\t\t\t\t(262, 0, 392, 131), (262, 131, 392, 262), (262, 262, 392, 392)]\n","\n","categories = ['bus', 'traffic lights', 'crosswalks', 'bicycles',\n","\t\t\t\t'a fire hydrant', 'cars', 'chimneys',\n","\t\t\t\t'parking meters', 'palm trees', 'stairs', 'bridges']\n","\n","#for root, dirs, files in os.walk(path):\n","#   for name in files:\n","#   \timage = load_img(os.path.join(root, name))\n","#   \tx = img_to_array(image)\n","#   \tx = x.reshape((1,)+x.shape)\n","#   \tmodel.predict(x)\n","   \t#print(x.shape)\n","   \t#i=0\n","   \t#for batch in datagen.flow(x, batch_size=1, save_to_dir=path, save_prefix='pic', save_format='jpg'):\n","   \t#\ti += 1\n","   \t#\tif i > 5:\n","   \t#\t\tbreak\n","   \t\n","\n","   \t#img = Image.open(os.path.join(root, name))\n","   \t#new_image = img.crop((538, 235, 930, 627))\n","   \t#for i in range(9):\n","   \t#\tfin_img = new_image.crop(mini_pic_sizes[i])\n","   \t#\tfin_img.save('/home/val/google_recaptcha_set/recaptcha_set/3x3/pic_{}.jpg'.format(j))\n","   \t\t#fin_img.show()\n","   \t#\tj += 1\n","   \t\t#time.sleep(15)\"\"\"\n","\n","\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9FrQbfrJpPgX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":124},"outputId":"2c860957-b0bc-48ed-f217-647d01243773","executionInfo":{"status":"ok","timestamp":1571314561196,"user_tz":-180,"elapsed":23238,"user":{"displayName":"Valentina Figurskaya","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC9898tz-Bcx7lz3a8qRwkMEU3TbfJsZmMT8BtX=s64","userId":"03885377616144133547"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JkDVkrL8Arz8","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}